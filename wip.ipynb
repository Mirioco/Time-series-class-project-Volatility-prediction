{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca97c82a-db57-4a78-a74b-a46dde1cf3ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f5ee2682-311a-426c-9891-24097a610316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from arch import arch_model\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a7c6c-c30c-4904-b0be-bcdce45ef593",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f344a7-e02e-46ea-92b3-c3fffc90e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp500_ticker_list():\n",
    "    \"\"\"\n",
    "    Returns a list with all SP500 tickers\n",
    "    \"\"\"\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    tables = pd.read_html(url)\n",
    "    table = tables[0]\n",
    "    ticker_list = table['Symbol']\n",
    "    return ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d289221-e4fa-4e3a-bc07-6830638f05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_ticker(ticker_list, n=5):\n",
    "    sample = ticker_list.sample(n).to_list()\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c159ed3d-6d6b-4898-8eb7-21a63ea8033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_close(ticker_list, start, end, interval):\n",
    "    \"\"\"\n",
    "    Returns the adjusted close for a unique ticker as string or a list of tickers.\n",
    "    Format of dates: 'yyyy-mm-dd'\n",
    "    Possible intervals: '1d', '5d', '1mo' \n",
    "    or intraday measures but limited to max a week's worth: '1m', '2m', '5m', '15m', '30m'\n",
    "    \"\"\"\n",
    "    full_df = yf.download(ticker_list, start=start, end=end, interval=interval)\n",
    "    adj_close_df = full_df['Adj Close']\n",
    "    return adj_close_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c710b41a-4774-48aa-a632-bd1367ad42d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_close_df(n=5, start='2020-01-01', end='2021-12-31', interval='1d'):\n",
    "    \"\"\"\n",
    "    Returns the returns df and adj close df for a unique ticker as string or a list of tickers.\n",
    "    n = sample size\n",
    "    Format of dates: 'yyyy-mm-dd'\n",
    "    Possible intervals: '1d', '5d', '1mo' \n",
    "    or intraday measures but limited to max a week's worth: '1m', '2m', '5m', '15m', '30m'\n",
    "    Returns a dataframe of a random sample of the sp500 adj closes over a certain period of time\n",
    "    \"\"\"\n",
    "    sp500_tickers = get_sp500_ticker_list()\n",
    "    sample_tickers = get_sample_ticker(sp500_tickers, n)\n",
    "    full_df = yf.download(sample_tickers, start=start, end=end, interval=interval)\n",
    "    adj_close_df = full_df['Adj Close']\n",
    "    return adj_close_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15fc8122-449d-4158-a61e-dc8186716896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  5 of 5 completed\n"
     ]
    }
   ],
   "source": [
    "adj_close_df = get_adj_close_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cd8a595f-ff46-41c8-b09c-6d0623473f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_returns(adj_close_df):\n",
    "    df_returns = (adj_close_df.pct_change())*100\n",
    "    df_returns.dropna(axis=0,inplace=True)\n",
    "    return df_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c9abab2-4c83-4345-81c1-38992bdd1f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df = get_returns(adj_close_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee75c5c7-4f83-49f7-8591-5a9f00df6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volatility(returns_df):\n",
    "    realized_vol = returns_df.rolling(5).std()\n",
    "    realized_vol.dropna(inplace=True)\n",
    "    return realized_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8665533d-9ff0-4411-9ce2-353497f76e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "volatility_df = get_volatility(returns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122f0f4b-bdbb-47c3-a7a8-10acf0c502ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Splitting the dataset by observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7512d4f0-7161-40ad-8497-cd0398cfb63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, n=50):\n",
    "    df_test = df.iloc[-n:]\n",
    "    df_train = df.iloc[:-n]\n",
    "    split_date = df.iloc[-n:].index\n",
    "    return df_train, df_test, split_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ccbd95d0-2748-4f69-a18a-051759f77b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_vol, df_test_vol, split_date = split_df(volatility_df)\n",
    "df_train_ret, df_test_ret, split_date = split_df(returns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b886ff03-d137-424a-9aec-a7fe2ec31e20",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "55db306a-fda7-4d9f-9312-d07616a678ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def garch(returns, n):\n",
    "\n",
    "    aic_garch = []\n",
    "\n",
    "    for p in range(1, 2): \n",
    "        for q in range(1, 2):\n",
    "            garch = arch_model(returns, mean='zero', vol='GARCH', p=p, q=q)\\\n",
    "                .fit(disp='off') \n",
    "            aic_garch.append(garch.aic) \n",
    "\n",
    "            if garch.aic == np.min(aic_garch): \n",
    "                best_param = (p,q) \n",
    "    \n",
    "    #fitting the best GARCH model\n",
    "    garch = arch_model(returns, mean='zero', vol='GARCH', p=best_param[0], q=best_param[1]).fit(disp='off')\n",
    "\n",
    "    #forecasts\n",
    "    forecasts = garch.forecast(horizon=n, reindex=False)\n",
    "    #forecasts = garch.forecast(horizon=50, start=split_date[0], reindex=True)\n",
    "    return forecasts, forecasts.residual_variance.dropna().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "6971be9b-5c96-46a7-9c2d-cfb9a027fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts, residuals = garch(df_train_ret.iloc[:, :1], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "74fcb02f-c800-49a7-9169-db355ed826eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(residuals, df_test):\n",
    "    rmse = np.sqrt(mse(df_test.iloc[:, :1]/100, np.sqrt(residuals/100)))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d127d69f-02c5-4c79-9bf9-7f036f638336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2205656102776126"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(residuals, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e0654b-9881-4e37-a5ed-f555044a04de",
   "metadata": {},
   "source": [
    "### ARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "3c404755-90af-42d3-bf87-d6617e57af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arch(returns, n):\n",
    "    aic_arch = []\n",
    "\n",
    "    for p in range(1, 2): # Iterating ARCH parameter p\n",
    "        arch = arch_model(returns, mean='zero', vol='ARCH', p=p)\\\n",
    "             .fit(disp='off') # Running ARCH(p)\n",
    "        aic_arch.append(arch.aic) # Storing aic for the ARCH(p)\n",
    "\n",
    "        if arch.aic == np.min(aic_arch): \n",
    "             best_param = p # Finding the minimum AIC score\n",
    "                \n",
    "    # Fitting best arch\n",
    "    arch = arch_model(returns, mean='zero', vol='ARCH', p=best_param)\\\n",
    "         .fit(disp='off')\n",
    "    \n",
    "    forecasts = arch.forecast(horizon=n, reindex=False)\n",
    "    \n",
    "    return forecasts, forecasts.residual_variance.dropna().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "47761e31-f483-4539-ab51-83e379a549b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts, residuals = garch(df_train_ret.iloc[:, :1], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "5c39bfa7-5d71-4eec-b82d-661d1af930f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2205656102776126"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(residuals, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85028aa3-61b1-4c1c-b630-5fc70f4087af",
   "metadata": {},
   "source": [
    "### GJR garch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "2fc0c467-5731-4172-bf12-950a36962769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gjr_garch(returns, n):\n",
    "    aic_gjr_garch = []\n",
    "\n",
    "    for p in range(1, 2): \n",
    "        for q in range(1, 2):\n",
    "            gjr_garch = arch_model(returns, mean='zero', vol='GARCH', p=p, o=1, q=q)\\\n",
    "                 .fit(disp='off') \n",
    "            aic_gjr_garch.append(gjr_garch.aic) \n",
    "\n",
    "            if gjr_garch.aic == np.min(aic_gjr_garch): \n",
    "                 best_param = p, q # Finding the minimum AIC score\n",
    "    \n",
    "    gjr_garch = arch_model(returns, mean='zero', vol='ARCH', p=best_param[0], o=1,\n",
    "                       q=best_param[1]).fit(disp='off')\n",
    "    \n",
    "    forecasts = gjr_garch.forecast(horizon=n, reindex=True)\n",
    "    \n",
    "    return forecasts, forecasts.residual_variance.dropna().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "92c9ade8-d6d3-42c8-9a9d-7406b95c921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts, residuals = gjr_garch(df_train_ret.iloc[:, :1], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "149c6b33-0337-450f-a9fb-eb1d2d67c69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20397548607626004"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(residuals, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42224fd5-729f-4f6f-83c4-93817b55b844",
   "metadata": {},
   "source": [
    "### EGARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "75145c60-8213-4f60-acc2-ed11298e0998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def egarch(returns, n):\n",
    "    aic_egarch = []\n",
    "\n",
    "    for p in range(1, 2):\n",
    "        for q in range(1, 2):\n",
    "            egarch = arch_model(returns, mean='zero', vol='EGARCH', p=p, q=q)\\\n",
    "                  .fit(disp='off')\n",
    "            aic_egarch.append(egarch.aic)\n",
    "            if egarch.aic == np.min(aic_egarch):\n",
    "                best_param = (p, q)\n",
    "    \n",
    "    egarch = arch_model(returns, mean='zero', vol='EGARCH',\n",
    "                        p=best_param[0], q=best_param[1], dist=\"skewt\").fit(disp='off')\n",
    "    \n",
    "    forecasts = egarch.forecast(horizon=50, method='simulation', reindex=False)\n",
    "    \n",
    "    return forecasts, forecasts.residual_variance.dropna().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d3beb511-c253-4cb9-b833-bf71d924fdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts, residuals = egarch(df_train_ret.iloc[:, :1], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "1a23de8e-6f1f-4199-bcce-fbd4f7d7dc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23406873545174414"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(residuals, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcaeb47-52a5-4828-94cf-1f4c025faf2e",
   "metadata": {},
   "source": [
    "### Neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af32376-5ab2-4199-bbf2-14a883f8ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
