{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca97c82a-db57-4a78-a74b-a46dde1cf3ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "f5ee2682-311a-426c-9891-24097a610316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from arch import arch_model\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a7c6c-c30c-4904-b0be-bcdce45ef593",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f344a7-e02e-46ea-92b3-c3fffc90e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp500_ticker_list():\n",
    "    \"\"\"\n",
    "    Returns a list with all SP500 tickers\n",
    "    \"\"\"\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    tables = pd.read_html(url)\n",
    "    table = tables[0]\n",
    "    ticker_list = table['Symbol']\n",
    "    return ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "2d289221-e4fa-4e3a-bc07-6830638f05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_ticker(ticker_list, s=5):\n",
    "    sample = ticker_list.sample(s).to_list()\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c159ed3d-6d6b-4898-8eb7-21a63ea8033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_close(ticker_list, start, end, interval):\n",
    "    \"\"\"\n",
    "    Returns the adjusted close for a unique ticker as string or a list of tickers.\n",
    "    Format of dates: 'yyyy-mm-dd'\n",
    "    Possible intervals: '1d', '5d', '1mo' \n",
    "    or intraday measures but limited to max a week's worth: '1m', '2m', '5m', '15m', '30m'\n",
    "    \"\"\"\n",
    "    full_df = yf.download(ticker_list, start=start, end=end, interval=interval)\n",
    "    adj_close_df = full_df['Adj Close']\n",
    "    return adj_close_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "c710b41a-4774-48aa-a632-bd1367ad42d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_close_df(s=5, start='2020-01-01', end='2021-12-31', interval='1d'):\n",
    "    \"\"\"\n",
    "    Returns the returns df and adj close df for a unique ticker as string or a list of tickers.\n",
    "    n = sample size\n",
    "    Format of dates: 'yyyy-mm-dd'\n",
    "    Possible intervals: '1d', '5d', '1mo' \n",
    "    or intraday measures but limited to max a week's worth: '1m', '2m', '5m', '15m', '30m'\n",
    "    Returns a dataframe of a random sample of the sp500 adj closes over a certain period of time\n",
    "    \"\"\"\n",
    "    sp500_tickers = get_sp500_ticker_list()\n",
    "    sample_tickers = get_sample_ticker(sp500_tickers, s)\n",
    "    full_df = yf.download(sample_tickers, start=start, end=end, interval=interval)\n",
    "    adj_close_df = full_df['Adj Close']\n",
    "    return adj_close_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15fc8122-449d-4158-a61e-dc8186716896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  5 of 5 completed\n"
     ]
    }
   ],
   "source": [
    "adj_close_df = get_adj_close_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cd8a595f-ff46-41c8-b09c-6d0623473f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_returns(adj_close_df):\n",
    "    df_returns = (adj_close_df.pct_change())*100\n",
    "    df_returns.dropna(axis=0,inplace=True)\n",
    "    return df_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c9abab2-4c83-4345-81c1-38992bdd1f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df = get_returns(adj_close_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee75c5c7-4f83-49f7-8591-5a9f00df6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volatility(returns_df):\n",
    "    realized_vol = returns_df.rolling(5).std()\n",
    "    realized_vol.dropna(inplace=True)\n",
    "    return realized_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "8665533d-9ff0-4411-9ce2-353497f76e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "volatility_df = get_volatility(returns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122f0f4b-bdbb-47c3-a7a8-10acf0c502ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Splitting the dataset by observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7512d4f0-7161-40ad-8497-cd0398cfb63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, n=50):\n",
    "    df_test = df.iloc[-n:]\n",
    "    df_train = df.iloc[:-n]\n",
    "    split_date = df.iloc[-n:].index\n",
    "    return df_train, df_test, split_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ccbd95d0-2748-4f69-a18a-051759f77b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_vol, df_test_vol, split_date = split_df(volatility_df)\n",
    "df_train_ret, df_test_ret, split_date = split_df(returns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b886ff03-d137-424a-9aec-a7fe2ec31e20",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "55db306a-fda7-4d9f-9312-d07616a678ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def garch(returns, n):\n",
    "\n",
    "    aic_garch = []\n",
    "\n",
    "    for p in range(1, 2): \n",
    "        for q in range(1, 2):\n",
    "            garch = arch_model(returns, mean='zero', vol='GARCH', p=p, q=q)\\\n",
    "                .fit(disp='off') \n",
    "            aic_garch.append(garch.aic) \n",
    "\n",
    "            if garch.aic == np.min(aic_garch): \n",
    "                best_param = (p,q) \n",
    "    \n",
    "    #fitting the best GARCH model\n",
    "    garch = arch_model(returns, mean='zero', vol='GARCH', p=best_param[0], q=best_param[1]).fit(disp='off')\n",
    "\n",
    "    #forecasts\n",
    "    forecasts = garch.forecast(horizon=n, reindex=False)\n",
    "    #forecasts = garch.forecast(horizon=50, start=split_date[0], reindex=True)\n",
    "    return forecasts, forecasts.residual_variance.dropna().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "6971be9b-5c96-46a7-9c2d-cfb9a027fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts, residuals = garch(df_train_ret.iloc[:, :1], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "74fcb02f-c800-49a7-9169-db355ed826eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(residuals, realized_vol):\n",
    "    rmse = np.sqrt(mse(realized_vol/100, np.sqrt(residuals/100)))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d127d69f-02c5-4c79-9bf9-7f036f638336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2205656102776126"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(residuals, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e0654b-9881-4e37-a5ed-f555044a04de",
   "metadata": {},
   "source": [
    "### ARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "3c404755-90af-42d3-bf87-d6617e57af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arch(returns, n):\n",
    "    aic_arch = []\n",
    "\n",
    "    for p in range(1, 2): # Iterating ARCH parameter p\n",
    "        arch = arch_model(returns, mean='zero', vol='ARCH', p=p)\\\n",
    "             .fit(disp='off') # Running ARCH(p)\n",
    "        aic_arch.append(arch.aic) # Storing aic for the ARCH(p)\n",
    "\n",
    "        if arch.aic == np.min(aic_arch): \n",
    "             best_param = p # Finding the minimum AIC score\n",
    "                \n",
    "    # Fitting best arch\n",
    "    arch = arch_model(returns, mean='zero', vol='ARCH', p=best_param)\\\n",
    "         .fit(disp='off')\n",
    "    \n",
    "    forecasts = arch.forecast(horizon=n, reindex=False)\n",
    "    \n",
    "    return forecasts, forecasts.residual_variance.dropna().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "47761e31-f483-4539-ab51-83e379a549b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts, residuals = garch(df_train_ret.iloc[:, :1], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "5c39bfa7-5d71-4eec-b82d-661d1af930f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2205656102776126"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(residuals, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85028aa3-61b1-4c1c-b630-5fc70f4087af",
   "metadata": {},
   "source": [
    "### GJR garch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "2fc0c467-5731-4172-bf12-950a36962769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gjr_garch(returns, n):\n",
    "    aic_gjr_garch = []\n",
    "\n",
    "    for p in range(1, 2): \n",
    "        for q in range(1, 2):\n",
    "            gjr_garch = arch_model(returns, mean='zero', vol='GARCH', p=p, o=1, q=q)\\\n",
    "                 .fit(disp='off') \n",
    "            aic_gjr_garch.append(gjr_garch.aic) \n",
    "\n",
    "            if gjr_garch.aic == np.min(aic_gjr_garch): \n",
    "                 best_param = p, q # Finding the minimum AIC score\n",
    "    \n",
    "    gjr_garch = arch_model(returns, mean='zero', vol='ARCH', p=best_param[0], o=1,\n",
    "                       q=best_param[1]).fit(disp='off')\n",
    "    \n",
    "    forecasts = gjr_garch.forecast(horizon=n, reindex=True)\n",
    "    \n",
    "    return forecasts, forecasts.residual_variance.dropna().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "92c9ade8-d6d3-42c8-9a9d-7406b95c921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts, residuals = gjr_garch(df_train_ret.iloc[:, :1], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "149c6b33-0337-450f-a9fb-eb1d2d67c69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20397548607626004"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(residuals, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42224fd5-729f-4f6f-83c4-93817b55b844",
   "metadata": {},
   "source": [
    "### EGARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "75145c60-8213-4f60-acc2-ed11298e0998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def egarch(returns, n):\n",
    "    aic_egarch = []\n",
    "\n",
    "    for p in range(1, 2):\n",
    "        for q in range(1, 2):\n",
    "            egarch = arch_model(returns, mean='zero', vol='EGARCH', p=p, q=q)\\\n",
    "                  .fit(disp='off')\n",
    "            aic_egarch.append(egarch.aic)\n",
    "            if egarch.aic == np.min(aic_egarch):\n",
    "                best_param = (p, q)\n",
    "    \n",
    "    egarch = arch_model(returns, mean='zero', vol='EGARCH',\n",
    "                        p=best_param[0], q=best_param[1], dist=\"skewt\").fit(disp='off')\n",
    "    \n",
    "    forecasts = egarch.forecast(horizon=50, method='simulation', reindex=False)\n",
    "    \n",
    "    return forecasts, forecasts.residual_variance.dropna().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d3beb511-c253-4cb9-b833-bf71d924fdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts, residuals = egarch(df_train_ret.iloc[:, :1], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "1a23de8e-6f1f-4199-bcce-fbd4f7d7dc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23406873545174414"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(residuals, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcaeb47-52a5-4828-94cf-1f4c025faf2e",
   "metadata": {},
   "source": [
    "### Neural nets, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "3af32376-5ab2-4199-bbf2-14a883f8ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svm_volatility(volatility_df):\n",
    "    realized_vol = {}\n",
    "    for ticker in volatility_df.columns:\n",
    "        realized_vol[ticker] = pd.DataFrame(volatility_df[ticker]).reset_index(drop=True)\n",
    "    return realized_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "4f6f3202-7ac9-4c62-a4e3-5c4310b04a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svm_returns(returns_df):\n",
    "    returns_svm = {}\n",
    "    for ticker in returns_df.columns:\n",
    "        returns_svm[ticker] = returns_df[ticker]**2\n",
    "        returns_svm[ticker] = returns_svm[ticker].reset_index()\n",
    "        del returns_svm[ticker]['Date']\n",
    "    return returns_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "c8a07ca1-158e-476d-bf0c-cd26ee4c6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_ret_vol(returns_df, volatility_df):\n",
    "    Xs = {}\n",
    "    realized_vol = get_svm_volatility(volatility_df)#[:-4]\n",
    "    returns_svm = get_svm_returns(returns_df)\n",
    "    for ticker in volatility_df.keys():\n",
    "        Xs[ticker] = pd.concat([realized_vol[ticker], returns_svm[ticker][:-4]], axis=1, ignore_index=True)\n",
    "        \n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "0e2e0135-5166-4628-a2ca-734c5814eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = concat_ret_vol(returns_df, volatility_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "13411b68-30e5-4b85-8164-439b5e6241aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_train_test_svm(Xs, n=50):\n",
    "#     Xs_splitted = {}\n",
    "#     for ticker, X in Xs.items():\n",
    "#         Xs_splitted[ticker] = {}\n",
    "#         Xs_splitted[ticker]['train'] = X.iloc[:-n]\n",
    "#         Xs_splitted[ticker]['test'] = X.iloc[-n:]\n",
    "#     return Xs_splitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111b849e-65f4-41ca-8987-f73b337ea51b",
   "metadata": {},
   "source": [
    "<!-- Xs_splitted = get_train_test_svm(Xs, n=50) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7481f1f9-8eb9-443a-bda2-5b4ec3854032",
   "metadata": {},
   "source": [
    "### Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "3ebb28f8-3c2c-4f50-988e-ac6d5ed623fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_vol = MLPRegressor(learning_rate_init=0.001, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "db882e6f-ffce-4213-a529-a5ecdc695154",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_grid_NN = {'hidden_layer_sizes': [(100, 50), (50, 50), (10, 100)],\n",
    "                'max_iter': [500, 1000],\n",
    "                'alpha': [0.00005, 0.0005 ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "056e48ee-a7c5-4025-96b8-ad7734576a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomizedSearchCV(NN_vol, para_grid_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "93722739-fc91-40ad-a5d7-4c91d363c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(Xs, n=50):\n",
    "    X_predictions = {}\n",
    "    for ticker, X in Xs.items():\n",
    "        realized_vol = X[0]\n",
    "        clf = RandomizedSearchCV(NN_vol, para_grid_NN)\n",
    "        clf.fit(X.iloc[:-n].values,\n",
    "            realized_vol.iloc[1:-(n-1)].values.reshape(-1, ))\n",
    "        X_predictions[ticker] = clf.predict(X.iloc[-n:])\n",
    "    return X_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "10486c6a-e2d5-4033-945f-156ec41af655",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predictions = neural_net(Xs_splitted, n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc89b1-4cf6-43c4-a1d3-475ab7f29c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "68da03ff-9905-46f6-9502-760fba203aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.16530353, 1.22485074, 1.02747157, 0.90250107, 0.89371821,\n",
       "       0.79185244, 0.73967724, 1.04380431, 1.25407036, 1.25634262,\n",
       "       1.63844025, 1.68082139, 2.04213559, 1.93606472, 1.6898283 ,\n",
       "       2.10746934, 1.32340398, 2.04412487, 2.0340602 , 1.87257907,\n",
       "       1.26845727, 0.95259769, 1.24938606, 1.68516381, 1.8859812 ,\n",
       "       1.9106961 , 1.67152201, 2.3004118 , 2.52611034, 2.67652743,\n",
       "       2.90530969, 4.7545577 , 4.21062848, 5.16119125, 5.13596104,\n",
       "       3.65973335, 3.1468498 , 2.55450584, 3.98834018, 4.34798576,\n",
       "       6.48210942, 5.2853198 , 4.25302711, 5.26657878, 3.12514948,\n",
       "       1.30989628, 1.05252282, 1.07423454, 1.13466524, 1.10235344])"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_predictions['ADBE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "0903e8dd-26e3-49d6-822a-b38b37d40c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mse(df_test['ADBE'] / 100,\n",
    "                   X_predictions['ADBE'] / 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "60954f36-1b20-4136-afac-f70161b4162f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0033607729900200665"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "3b6cf6b1-19ce-40ef-9f95-34ccb7101376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmses(s, n, start, end, interval):\n",
    "    \"\"\"\n",
    "    s = how many companies\n",
    "    n = sample size for testing\n",
    "    \"\"\"\n",
    "    NN_vol = MLPRegressor(learning_rate_init=0.001, random_state=1)\n",
    "    para_grid_NN = {'hidden_layer_sizes': [(100, 50), (50, 50), (10, 100)],\n",
    "                'max_iter': [500, 1000],\n",
    "                'alpha': [0.00005, 0.0005 ]}\n",
    "    rmses = {}\n",
    "    \n",
    "    # Get data\n",
    "    adj_close_df = get_adj_close_df(s=s, start=start, end=end, interval=interval)\n",
    "    \n",
    "    # Get returns and volatility for arch type models\n",
    "    returns_df = get_returns(adj_close_df)\n",
    "    volatility_df = get_volatility(returns_df)\n",
    "    \n",
    "    # Splitting sets for arch type models\n",
    "    df_train_vol, df_test_vol, split_date = split_df(volatility_df, n)\n",
    "    df_train_ret, df_test_ret, split_date = split_df(returns_df, n)\n",
    "    \n",
    "    # Neural net preprocessing\n",
    "    Xs = concat_ret_vol(returns_df, volatility_df)\n",
    "    nn_predictions = neural_net(Xs, n=n)\n",
    "    \n",
    "    # Getting rmses\n",
    "    for ticker in df_test_vol.columns:\n",
    "        rmses[ticker] = {}\n",
    "        \n",
    "        #Neural net\n",
    "        rmses[ticker]['nn'] = np.sqrt(mse(df_test_vol[ticker] / 100, nn_predictions[ticker] / 100))\n",
    "        \n",
    "#         #Garch\n",
    "#         forecasts, residuals = garch(df_train_ret[ticker], n)\n",
    "#         rmses[ticker]['garch'] = get_rmse(residuals, df_test_vol[ticker])\n",
    "        \n",
    "#         #Arch\n",
    "#         forecasts, residuals = garch(df_train_ret[ticker], n)\n",
    "#         rmses[ticker]['arch'] = get_rmse(residuals, df_test_vol[ticker])\n",
    "        \n",
    "#         #GJR-garch\n",
    "#         forecasts, residuals = gjr_garch(df_train_ret[ticker], n)\n",
    "#         rmses[ticker]['gjr_garch'] = get_rmse(residuals, df_test_vol[ticker])\n",
    "        \n",
    "#         #Egarch\n",
    "#         forecasts, residuals = egarch(df_train_ret[ticker], n)\n",
    "#         rmses[ticker]['egarch'] = get_rmse(residuals, df_test_vol[ticker])\n",
    "        \n",
    "    return rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26a673-6ab6-4097-9f17-10221c1b1aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n"
     ]
    }
   ],
   "source": [
    "get_rmses(s=2, n=50, start='2020-01-01', end='2021-12-31', interval='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77b4136-9eb2-4e16-a18b-8ef247b0d2df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
